#!/usr/bin/env python3
"""
éŸ³é¢‘å½•åˆ¶å’Œå¤„ç†æ¨¡å—
"""

import sounddevice as sd
import numpy as np
import threading
import time
import queue
import hashlib
import json
from pathlib import Path
from vad_processor import VADProcessor
from speech_recognizer import SpeechRecognizer

class AudioRecorder:
    def __init__(self, 
                 audio_device_id=0,
                 samplerate=16000,
                 channels=2,
                 blocksize=1024,
                 silence_timeout=1.5,
                 min_speech_duration=0.5,
                 enable_asr=True,
                 asr_queue_size=20,
                 save_recordings=True,
                 recording_cache_dir="recording_cache",
                 max_cache_files=50,
                 device="cpu"):
        """
        åˆå§‹åŒ–éŸ³é¢‘å½•åˆ¶å™¨
        
        Args:
            audio_device_id: éŸ³é¢‘è®¾å¤‡ID
            samplerate: é‡‡æ ·ç‡
            channels: å£°é“æ•°
            blocksize: éŸ³é¢‘å—å¤§å°
            silence_timeout: é™éŸ³è¶…æ—¶æ—¶é—´(ç§’)
            min_speech_duration: æœ€å°è¯­éŸ³æ—¶é•¿(ç§’)
            enable_asr: å¯ç”¨è¯­éŸ³è¯†åˆ«
            asr_queue_size: ASRé˜Ÿåˆ—å¤§å°
            save_recordings: æ˜¯å¦ä¿å­˜å½•åˆ¶æ–‡ä»¶ (æ–°å¢)
            recording_cache_dir: å½•åˆ¶ç¼“å­˜ç›®å½• (æ–°å¢)
            max_cache_files: æœ€å¤§ç¼“å­˜æ–‡ä»¶æ•°é‡ (æ–°å¢)
            device: AIæ¨¡å‹è¿è¡Œè®¾å¤‡ (cpu/cuda:0/auto)
        """
        # éŸ³é¢‘å‚æ•°
        self.audio_device_id = audio_device_id
        self.samplerate = samplerate
        self.channels = channels
        self.blocksize = blocksize
        self.silence_timeout = silence_timeout
        self.min_speech_duration = min_speech_duration
        self.enable_asr = enable_asr
        self.asr_queue_size = asr_queue_size
        self.save_recordings = save_recordings
        self.max_cache_files = max_cache_files
        
        # å½•åˆ¶ç¼“å­˜ç®¡ç†
        self.recording_cache_dir = Path(recording_cache_dir)
        self.recording_cache_dir.mkdir(exist_ok=True)
        self.recording_cache_index_file = self.recording_cache_dir / "recording_index.json"
        self.recording_cache_index = self._load_recording_cache_index()
        
        # çŠ¶æ€å˜é‡
        self.recording_active = True
        self.is_paused = False  # æš‚åœçŠ¶æ€
        self.audio_stream = None  # éŸ³é¢‘æµå¼•ç”¨
        self.audio_buffer = []
        self.last_active_time = time.time()
        
        # çº¿ç¨‹é”
        self._buffer_lock = threading.Lock()  # ä¿æŠ¤éŸ³é¢‘ç¼“å†²åŒºçš„çº¿ç¨‹é”
        
        # å½•åˆ¶ç»Ÿè®¡
        self.recording_stats = {
            'total_recordings': 0,
            'successful_recognitions': 0,
            'failed_recognitions': 0,
            'short_recordings': 0,
            'cached_files': len(self.recording_cache_index)
        }
        
        # è¯­éŸ³å½•åˆ¶çŠ¶æ€
        self.speech_segments = []
        self.is_recording_speech = False
        self.speech_start_time = None
        self.is_processing = False
        self.actual_speech_duration = 0.0
        
        # æ§åˆ¶å¾…æœºçŠ¶æ€æ˜¾ç¤º
        self.show_standby_status = True
        
        # è¿ç»­è¯­éŸ³æ£€æµ‹è®¡æ•°å™¨ (å‡å°‘è¯¯è§¦å‘)
        self.consecutive_speech_count = 0
        self.speech_confirmation_threshold = 2  # éœ€è¦è¿ç»­2æ¬¡æ£€æµ‹åˆ°è¯­éŸ³æ‰å¼€å§‹å½•åˆ¶
        
        # åˆå§‹åŒ–VADå¤„ç†å™¨ (æ¨¡å¼1: ä¸å¤ªæ•æ„Ÿï¼Œå‡å°‘è¯¯è§¦å‘)
        self.vad_processor = VADProcessor(
            vad_mode=1, 
            samplerate=samplerate, 
            channels=channels
        )
        
        # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
        self.speech_recognizer = None
        if enable_asr:
            self.speech_recognizer = SpeechRecognizer(samplerate=samplerate, device=device)
            if not self.speech_recognizer.is_model_loaded():
                self.enable_asr = False
        
        # ASRé˜Ÿåˆ—ç®¡ç†
        self.asr_queue = queue.Queue(maxsize=asr_queue_size)
        self.asr_consumer_active = True
        self.asr_stats = {
            'queued': 0,
            'processed': 0,
            'dropped': 0
        }
        
        # å›è°ƒå‡½æ•°
        self.on_speech_detected = None
        self.on_silence_detected = None
        self.on_recognition_result = None
        
        # å¯åŠ¨æ—¶æ¸…ç†ç¼“å­˜ï¼Œç¡®ä¿æ–‡ä»¶æ•°é‡åœ¨é™åˆ¶å†…
        if len(self.recording_cache_index) > self.max_cache_files:
            self._cleanup_recording_cache()
        
        print('âœ… éŸ³é¢‘å½•åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ')
        print(f'ğŸ“ å½•åˆ¶ç¼“å­˜ç›®å½•: {self.recording_cache_dir.absolute()}')
        print(f'ğŸ“Š å½“å‰ç¼“å­˜æ–‡ä»¶: {len(self.recording_cache_index)} / {self.max_cache_files}')
    
    def _load_recording_cache_index(self):
        """åŠ è½½å½•åˆ¶ç¼“å­˜ç´¢å¼•"""
        try:
            if self.recording_cache_index_file.exists():
                with open(self.recording_cache_index_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å½•åˆ¶ç¼“å­˜ç´¢å¼•å¤±è´¥: {e}")
        return {}
    
    def _save_recording_cache_index(self):
        """ä¿å­˜å½•åˆ¶ç¼“å­˜ç´¢å¼•"""
        try:
            with open(self.recording_cache_index_file, 'w', encoding='utf-8') as f:
                json.dump(self.recording_cache_index, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å½•åˆ¶ç¼“å­˜ç´¢å¼•å¤±è´¥: {e}")
    
    def _get_recording_hash(self, audio_data: bytes) -> str:
        """ç”Ÿæˆå½•åˆ¶éŸ³é¢‘çš„å“ˆå¸Œå€¼"""
        # ä½¿ç”¨éŸ³é¢‘æ•°æ®çš„MD5å“ˆå¸Œä½œä¸ºå”¯ä¸€æ ‡è¯†
        return hashlib.md5(audio_data).hexdigest()
    
    def _cleanup_recording_cache(self):
        """æ¸…ç†å½•åˆ¶ç¼“å­˜ï¼Œä¿æŒåœ¨æœ€å¤§æ•°é‡é™åˆ¶å†…"""
        if len(self.recording_cache_index) <= self.max_cache_files:
            return
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„æ–‡ä»¶
        sorted_items = sorted(
            self.recording_cache_index.items(),
            key=lambda x: x[1].get('created', 0)
        )
        
        files_to_remove = len(self.recording_cache_index) - self.max_cache_files
        for i in range(files_to_remove):
            hash_key, file_info = sorted_items[i]
            file_path = self.recording_cache_dir / file_info['filename']
            
            try:
                if file_path.exists():
                    file_path.unlink()
                    # é™é»˜åˆ é™¤æ—§å½•åˆ¶
                    pass
                del self.recording_cache_index[hash_key]
            except Exception as e:
                # é™é»˜å¤„ç†åˆ é™¤å¤±è´¥
                pass
        
        self._save_recording_cache_index()
        # é™é»˜å®Œæˆæ¸…ç†
    
    def _save_recording_file(self, audio_data: bytes, recognized_text: str = None) -> str:
        """ä¿å­˜å½•åˆ¶æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶è·¯å¾„"""
        if not self.save_recordings:
            return None
            
        try:
            # ç”Ÿæˆå“ˆå¸Œå’Œæ–‡ä»¶å
            audio_hash = self._get_recording_hash(audio_data)
            timestamp = int(time.time())
            filename = f"rec_{timestamp}_{audio_hash[:8]}.wav"
            file_path = self.recording_cache_dir / filename
            
            # ä¿å­˜WAVæ–‡ä»¶
            if self.speech_recognizer:
                self.speech_recognizer.save_wav_file(str(file_path), audio_data)
            
            # è®¡ç®—å®é™…éŸ³é¢‘æ—¶é•¿ï¼ˆåŒ…å«é™éŸ³æ®µï¼‰
            actual_duration = len(audio_data) / (self.samplerate * 2)  # æ€»æ—¶é•¿ï¼ˆåŒ…å«é™éŸ³ï¼‰
            
            # æ›´æ–°ç¼“å­˜ç´¢å¼•
            self.recording_cache_index[audio_hash] = {
                'filename': filename,
                'created': timestamp,
                'text': recognized_text or "æœªè¯†åˆ«",
                'duration': actual_duration,  # å®é™…å½•åˆ¶æ—¶é•¿ï¼ˆåŒ…å«é™éŸ³ï¼‰
                'speech_duration': getattr(self, 'actual_speech_duration', 0),  # çº¯è¯­éŸ³æ—¶é•¿
                'size': len(audio_data),
                'recognition_success': recognized_text is not None,
                'contains_silence': True  # æ ‡è®°åŒ…å«é™éŸ³æ®µ
            }
            
            # æ¸…ç†æ—§ç¼“å­˜
            self._cleanup_recording_cache()
            self._save_recording_cache_index()
            
            # æ›´æ–°ç»Ÿè®¡
            self.recording_stats['total_recordings'] += 1
            if recognized_text:
                self.recording_stats['successful_recognitions'] += 1
            self.recording_stats['cached_files'] = len(self.recording_cache_index)
            
            # å½•åˆ¶æ–‡ä»¶ä¿¡æ¯å°†åœ¨å½•åˆ¶å®Œæˆæ—¶æ˜¾ç¤º
            return str(file_path)
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å½•åˆ¶æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def get_recording_stats(self) -> dict:
        """è·å–å½•åˆ¶ç»Ÿè®¡ä¿¡æ¯"""
        return self.recording_stats.copy()
    
    def find_recording_by_text(self, text: str) -> list:
        """æ ¹æ®è¯†åˆ«æ–‡æœ¬æŸ¥æ‰¾å½•åˆ¶æ–‡ä»¶"""
        results = []
        for hash_key, file_info in self.recording_cache_index.items():
            if text.lower() in file_info.get('text', '').lower():
                file_path = self.recording_cache_dir / file_info['filename']
                if file_path.exists():
                    results.append({
                        'hash': hash_key,
                        'file_path': str(file_path),
                        'text': file_info['text'],
                        'created': file_info['created'],
                        'duration': file_info.get('duration', 0)
                    })
        return results
    
    def set_callbacks(self, on_speech=None, on_silence=None, on_recognition=None):
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self.on_speech_detected = on_speech
        self.on_silence_detected = on_silence
        self.on_recognition_result = on_recognition
    
    def audio_callback(self, indata, frames, time_info, status):
        """éŸ³é¢‘æ•°æ®å›è°ƒå‡½æ•°"""
        if status:
            print(f"âš ï¸ éŸ³é¢‘çŠ¶æ€è­¦å‘Š: {status}")
        
        # å¦‚æœæš‚åœï¼Œæ¸…ç©ºç¼“å†²åŒºå¹¶è¿”å›ï¼Œä¸å¤„ç†éŸ³é¢‘æ•°æ®
        if self.is_paused:
            with self._buffer_lock:
                self.audio_buffer.clear()
            return
        
        if self.recording_active:
            try:
                # æ­£ç¡®çš„éŸ³é¢‘æ ¼å¼è½¬æ¢æ–¹å¼ - é¿å…éŸ³è´¨æŸå¤±
                # ç¡®ä¿è¾“å…¥æ•°æ®æ˜¯æ­£ç¡®çš„æ ¼å¼
                if indata.ndim == 1:
                    # å•å£°é“æ•°æ®ï¼Œæ‰©å±•ä¸ºåŒå£°é“
                    audio_array = np.column_stack((indata, indata))
                else:
                    audio_array = indata
                
                # é™åˆ¶èŒƒå›´åˆ°[-1, 1]ç„¶åè½¬æ¢ä¸ºint16ï¼Œé¿å…æº¢å‡ºå’ŒéŸ³è´¨æŸå¤±
                audio_clipped = np.clip(audio_array, -1.0, 1.0)
                audio_data = (audio_clipped * 32767).astype(np.int16).tobytes()
                
                # æ·»åŠ åˆ°ç¼“å†²åŒº
                self.audio_buffer.append(audio_data)
                
                # æ¯0.3ç§’æ£€æµ‹ä¸€æ¬¡VAD
                buffer_duration = len(self.audio_buffer) * self.blocksize / self.samplerate
                if buffer_duration >= 0.3:
                    self.process_audio_buffer()
            
            except Exception as e:
                print(f"âŒ éŸ³é¢‘å›è°ƒå¤„ç†é”™è¯¯: {e}")
    
    def process_audio_buffer(self):
        """å¤„ç†éŸ³é¢‘ç¼“å†²åŒº"""
        # å¦‚æœæš‚åœï¼Œä¸å¤„ç†éŸ³é¢‘ç¼“å†²åŒº
        if self.is_paused:
            return
            
        # æ‹¼æ¥éŸ³é¢‘æ•°æ®å¹¶æ£€æµ‹VAD
        with self._buffer_lock:
            raw_audio = b''.join(self.audio_buffer)
        
        # è½¬æ¢ä¸ºå•å£°é“ï¼ˆç”¨äºä¿å­˜å½•åˆ¶æ–‡ä»¶ï¼‰
        if self.channels == 1:
            mono_audio = raw_audio
        else:
            mono_audio = self.vad_processor.stereo_to_mono(raw_audio)
        
        vad_result, speech_chunks, total_chunks = self.vad_processor.check_vad_activity(raw_audio)
        
        # è®¡ç®—éŸ³é¢‘å¹…åº¦
        amplitude = self.vad_processor.calculate_audio_amplitude(raw_audio)
        
        # è·å–å½“å‰æ—¶é—´
        current_time = time.time()
        
        # å¢åŠ å¹…åº¦é˜ˆå€¼è¿‡æ»¤ï¼Œå‡å°‘è¯¯è§¦å‘ (è°ƒæ•´è¿™ä¸ªå€¼æ¥æ§åˆ¶æ•æ„Ÿåº¦)
        amplitude_threshold = 0.1  # å¹…åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„éŸ³é¢‘ä¸ä¼šè§¦å‘å½•åˆ¶ï¼ˆå¯é…ç½®å‚æ•°ï¼‰
        
        if vad_result and amplitude > amplitude_threshold:
            self.consecutive_speech_count += 1
            
            # å¦‚æœè¿˜æ²¡å¼€å§‹å½•åˆ¶è¯­éŸ³ï¼Œéœ€è¦è¿ç»­æ£€æµ‹åˆ°è¯­éŸ³æ‰å¼€å§‹å½•åˆ¶
            if not self.is_recording_speech:
                if self.consecutive_speech_count >= self.speech_confirmation_threshold:
                    self.is_recording_speech = True
                    self.speech_start_time = current_time
                    self.speech_segments = []
                    self.actual_speech_duration = 0.0
                    self.show_standby_status = False  # åœæ­¢æ˜¾ç¤ºå¾…æœºçŠ¶æ€
                    print(f"\r\nğŸ”´ å¼€å§‹å½•åˆ¶è¯­éŸ³æ®µ", flush=True)
                else:
                    return  # è¿˜æœªç¡®è®¤ï¼Œä¸å¼€å§‹å½•åˆ¶
            
            # å½•åˆ¶è¿‡ç¨‹ä¸­ä¸æ˜¾ç¤ºå®æ—¶çŠ¶æ€
            self.last_active_time = current_time
            
            # æ·»åŠ åŸå§‹åŒå£°é“éŸ³é¢‘æ®µåˆ°è¯­éŸ³å½•åˆ¶ï¼ˆä¿æŒåŸå§‹éŸ³è´¨ï¼‰
            self.speech_segments.append(raw_audio)
            self.actual_speech_duration += 0.3
            
            # è°ƒç”¨å›è°ƒå‡½æ•°
            if self.on_speech_detected:
                self.on_speech_detected(amplitude, speech_chunks, total_chunks)
        else:
            # é‡ç½®è¿ç»­è¯­éŸ³è®¡æ•°å™¨
            self.consecutive_speech_count = 0
            
            # åªåœ¨æœªå½•åˆ¶æ—¶æ˜¾ç¤ºå¾…æœºçŠ¶æ€
            if not self.is_recording_speech and self.show_standby_status:
                print(f"\rğŸ”‡ å¾…æœºä¸­ - å¹…åº¦: {amplitude:.4f}, è¯­éŸ³å—: {speech_chunks}/{total_chunks}                    ", end="", flush=True)
            
            # é™éŸ³æ—¶ä¹Ÿæ·»åŠ éŸ³é¢‘æ®µï¼Œä¿æŒå®Œæ•´çš„å½•åˆ¶ä¸Šä¸‹æ–‡
            if self.is_recording_speech:
                self.speech_segments.append(raw_audio)  # æ·»åŠ é™éŸ³æ®µåˆ°å½•åˆ¶ï¼ˆä¿æŒåŸå§‹åŒå£°é“ï¼‰
                # æ³¨æ„ï¼šé™éŸ³æ®µä¸å¢åŠ actual_speech_durationï¼Œä½†ä¼šå¢åŠ æ€»å½•åˆ¶æ—¶é•¿
            
            # è°ƒç”¨å›è°ƒå‡½æ•°
            if self.on_silence_detected:
                self.on_silence_detected(amplitude, speech_chunks, total_chunks)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»“æŸå½•åˆ¶
        if (self.is_recording_speech and 
            current_time - self.last_active_time > self.silence_timeout and 
            not self.is_processing):
            
            # æ£€æŸ¥å®é™…è¯­éŸ³é•¿åº¦æ˜¯å¦æ»¡è¶³æœ€å°è¦æ±‚
            if self.actual_speech_duration >= self.min_speech_duration:
                # å½•åˆ¶å®Œæˆï¼Œç«‹å³æš‚åœå½•åˆ¶ï¼Œé¿å…åœ¨è¯†åˆ«å’ŒAIå¤„ç†æœŸé—´ç»§ç»­å½•åˆ¶
                self.is_paused = True
                self.show_standby_status = False
                self.process_speech_segments()
            else:
                # çŸ­è¯­éŸ³ç»Ÿè®¡
                self.recording_stats['short_recordings'] += 1
                print(f"\r\nâ­ï¸ è¯­éŸ³è¿‡çŸ­ [{self.actual_speech_duration:.1f}s/{self.min_speech_duration}s] å·²è·³è¿‡")
                print("-" * 50)  # åˆ†å‰²çº¿
                self.speech_segments.clear()
            
            self.is_recording_speech = False
            self.speech_start_time = None
            self.actual_speech_duration = 0.0
            # æ³¨æ„ï¼šå¦‚æœåˆšæ‰æˆåŠŸå½•åˆ¶äº†ï¼Œç°åœ¨æ˜¯æš‚åœçŠ¶æ€ï¼Œshow_standby_statusåº”è¯¥ä¸ºFalse
            # å¦‚æœæ˜¯çŸ­è¯­éŸ³è·³è¿‡ï¼Œshow_standby_statusåº”è¯¥ä¸ºTrue
            if not self.is_paused:  # å¦‚æœæ²¡æœ‰æš‚åœï¼ˆçŸ­è¯­éŸ³æƒ…å†µï¼‰ï¼Œæ¢å¤å¾…æœºçŠ¶æ€æ˜¾ç¤º
                self.show_standby_status = True
        
        # å¤„ç†å®Œæˆåæ¸…ç©ºç¼“å†²åŒº
        with self._buffer_lock:
            self.audio_buffer.clear()  # ä½¿ç”¨clear()æ›´å®‰å…¨
    
    def process_speech_segments(self):
        """å¤„ç†å’Œä¿å­˜è¯­éŸ³æ®µ"""
        if not self.speech_segments or self.is_processing:
            return
        
        self.is_processing = True
        
        try:
            # åˆå¹¶æ‰€æœ‰è¯­éŸ³æ®µ
            combined_audio = b''.join(self.speech_segments)
            
            # è½¬æ¢ä¸ºå•å£°é“
            mono_audio = self.vad_processor.stereo_to_mono(combined_audio)
            
            # è®¡ç®—éŸ³é¢‘ä¿¡æ¯
            audio_length = len(mono_audio) / (self.samplerate * 2)  # 2å­—èŠ‚per sample
            
            # å¦‚æœå¯ç”¨è¯­éŸ³è¯†åˆ«ï¼ŒåŠ å…¥é˜Ÿåˆ—è¿›è¡Œè¯†åˆ«
            if self.enable_asr and self.speech_recognizer:
                try:
                    audio_item = (mono_audio, audio_length, self.actual_speech_duration)
                    self.asr_queue.put_nowait(audio_item)
                    
                    self.asr_stats['queued'] += 1
                    queue_size = self.asr_queue.qsize()
                    
                    # éŸ³é¢‘æ®µå·²åŠ å…¥é˜Ÿåˆ—ï¼ˆå†…éƒ¨è°ƒè¯•ä¿¡æ¯ï¼Œä¸æ˜¾ç¤ºï¼‰
                    
                except queue.Full:
                    self.asr_stats['dropped'] += 1
                    print(f"âš ï¸ ASRé˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒå½“å‰éŸ³é¢‘æ®µ (æ—¶é•¿: {audio_length:.1f}s)")
            else:
                # ä¿å­˜æ–‡ä»¶ç”¨äºè°ƒè¯•
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                filename = f"speech_vad_{timestamp}.wav"
                self.speech_recognizer.save_wav_file(filename, mono_audio)
                print(f"ğŸ’¾ è¯­éŸ³æ–‡ä»¶å·²ä¿å­˜: {filename} (æ—¶é•¿: {audio_length:.1f}s)")
            
            # æ¸…ç©ºè¯­éŸ³æ®µç¼“å­˜
            self.speech_segments.clear()
            
        except Exception as e:
            print(f"âŒ å¤„ç†è¯­éŸ³æ®µå¤±è´¥: {e}")
        finally:
            self.is_processing = False
    
    def asr_consumer_worker(self):
        """ASRæ¶ˆè´¹è€…çº¿ç¨‹"""
        # ASRæ¶ˆè´¹è€…çº¿ç¨‹å¼€å§‹å·¥ä½œ
        
        while self.asr_consumer_active:
            try:
                audio_item = self.asr_queue.get(timeout=1.0)
                
                if audio_item is None:  # ç»“æŸä¿¡å·
                    break
                
                audio_data, audio_length, actual_speech_duration = audio_item
                
                self.asr_stats['processed'] += 1
                queue_size = self.asr_queue.qsize()
                
                # ä¸æ˜¾ç¤ºè¯†åˆ«ä¸­çŠ¶æ€ï¼Œä¿æŒç®€æ´
                
                # æ‰§è¡Œè¯­éŸ³è¯†åˆ«
                recognized_text = self.speech_recognizer.recognize_from_memory(audio_data)
                
                # ä¿å­˜å½•åˆ¶æ–‡ä»¶ï¼ˆä¸è¯†åˆ«ç»“æœå…³è”ï¼‰
                recording_file = self._save_recording_file(audio_data, recognized_text)
                
                # æ˜¾ç¤ºå½•åˆ¶æ–‡ä»¶ä¿å­˜ç»“æœ
                if recording_file:
                    from pathlib import Path
                    filename = Path(recording_file).name
                    if recognized_text and recognized_text.strip():
                        # è¯†åˆ«æˆåŠŸï¼Œæ˜¾ç¤ºå½•åˆ¶å®Œæˆå’Œè¯†åˆ«ç»“æœ
                        print(f"\râ¹ï¸ å½•åˆ¶å®Œæˆ ({audio_length:.1f}s) -> {filename}")
                        print(f"ğŸ™ï¸ è¯­éŸ³è¯†åˆ«: {recognized_text}")
                    else:
                        # è¯†åˆ«å¤±è´¥
                        self.recording_stats['failed_recognitions'] += 1
                        print(f"\râŒ è¯†åˆ«å¤±è´¥ -> {filename} ({audio_length:.1f}s)")
                        print("âš ï¸ è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œä½†å·²ä¿å­˜å½•åˆ¶æ–‡ä»¶ä»¥ä¾›è°ƒè¯•")
                        print("-" * 50)  # åˆ†å‰²çº¿
                        # è¯†åˆ«å¤±è´¥æ—¶æ¢å¤å½•åˆ¶
                        self._ensure_recording_resumed()
                
                # è°ƒç”¨è¯†åˆ«ç»“æœå›è°ƒï¼Œä¼ é€’å½•åˆ¶æ–‡ä»¶è·¯å¾„
                if recognized_text and recognized_text.strip() and self.on_recognition_result:
                    # å¦‚æœå›è°ƒå‡½æ•°æ”¯æŒå½•åˆ¶æ–‡ä»¶å‚æ•°ï¼Œä¼ é€’å®ƒ
                    try:
                        # å°è¯•ä¼ é€’é¢å¤–å‚æ•°
                        self.on_recognition_result(recognized_text, recording_file=recording_file)
                    except TypeError:
                        # å¦‚æœä¸æ”¯æŒé¢å¤–å‚æ•°ï¼Œä½¿ç”¨åŸå§‹æ–¹å¼
                        self.on_recognition_result(recognized_text)
                
                self.asr_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ ASRæ¶ˆè´¹è€…çº¿ç¨‹é”™è¯¯: {e}")
                # ASRå¼‚å¸¸æ—¶æ¢å¤å½•åˆ¶
                self._ensure_recording_resumed()
                # æ£€æŸ¥æ˜¯å¦æ˜¯å…³é”®é”™è¯¯
                if "memory" in str(e).lower() or "model" in str(e).lower():
                    print("ğŸš¨ æ£€æµ‹åˆ°å…³é”®é”™è¯¯ï¼Œåœæ­¢ASRå¤„ç†")
                    self.asr_consumer_active = False
                    break
                time.sleep(0.5)
        
        # ASRæ¶ˆè´¹è€…çº¿ç¨‹ç»“æŸ
    
    def pause_recording(self):
        """æš‚åœå½•åˆ¶ï¼ˆä¿æŒéŸ³é¢‘æµï¼Œä½†åœæ­¢å¤„ç†ï¼‰"""
        if not self.is_paused:
            self.is_paused = True
            self.show_standby_status = False  # TTSæ’­æ”¾æœŸé—´ä¸æ˜¾ç¤ºå¾…æœºçŠ¶æ€
            # æš‚åœå½•åˆ¶ï¼ˆå†…éƒ¨æ“ä½œï¼Œä¸æ˜¾ç¤ºæ—¥å¿—ï¼‰
    
    def resume_recording(self):
        """æ¢å¤å½•åˆ¶"""
        if self.is_paused:
            self.is_paused = False
            self.show_standby_status = True  # æ¢å¤å¾…æœºçŠ¶æ€æ˜¾ç¤º
            # æ¢å¤å½•åˆ¶ï¼ˆå†…éƒ¨æ“ä½œï¼Œä¸æ˜¾ç¤ºæ—¥å¿—ï¼‰
    
    def _ensure_recording_resumed(self):
        """ç¡®ä¿å½•åˆ¶å·²æ¢å¤ - å†…éƒ¨æ–¹æ³•ï¼Œç”¨äºè¯†åˆ«å¤±è´¥ç­‰æƒ…å†µ"""
        if self.is_paused:
            self.resume_recording()
    
    def start_recording(self):
        """å¼€å§‹å½•åˆ¶"""
        try:
            # å¼€å§‹éŸ³é¢‘VADç›‘å¬
            
            # å¯åŠ¨ASRæ¶ˆè´¹è€…çº¿ç¨‹
            if self.enable_asr:
                self.asr_thread = threading.Thread(target=self.asr_consumer_worker)
                self.asr_thread.daemon = True
                self.asr_thread.start()
                # ASRæ¶ˆè´¹è€…çº¿ç¨‹å¯åŠ¨å®Œæˆ
            
            # ä½¿ç”¨sounddeviceè¿›è¡ŒéŸ³é¢‘ç›‘å¬
            self.audio_stream = sd.InputStream(
                device=self.audio_device_id,
                channels=self.channels,
                samplerate=self.samplerate,
                blocksize=self.blocksize,
                dtype=np.float32,
                callback=self.audio_callback
            )
            
            with self.audio_stream:
                # æŒç»­ç›‘å¬
                while self.recording_active:
                    time.sleep(0.1)
            
        except Exception as e:
            print(f'âŒ éŸ³é¢‘VADç›‘å¬é”™è¯¯: {e}')
    
    def stop_recording(self):
        """åœæ­¢å½•åˆ¶"""
        self.recording_active = False
        # VADç›‘å¬åœæ­¢
        
        # å®‰å…¨å…³é—­éŸ³é¢‘æµ
        if hasattr(self, 'audio_stream') and self.audio_stream is not None:
            try:
                self.audio_stream.close()
                self.audio_stream = None
            except Exception as e:
                print(f"âš ï¸ å…³é—­éŸ³é¢‘æµå¤±è´¥: {e}")
        
        if self.enable_asr and hasattr(self, 'asr_queue'):
            self.asr_consumer_active = False
            try:
                # å‘é€åœæ­¢ä¿¡å·åˆ°ASRé˜Ÿåˆ—
                self.asr_queue.put_nowait(None)
                # ç­‰å¾…ASRçº¿ç¨‹ç»“æŸ
                if hasattr(self, 'asr_thread') and self.asr_thread.is_alive():
                    self.asr_thread.join(timeout=2.0)  # æœ€å¤šç­‰å¾…2ç§’
            except queue.Full:
                print("âš ï¸ ASRé˜Ÿåˆ—å·²æ»¡ï¼Œå¼ºåˆ¶åœæ­¢")
            except Exception as e:
                print(f"âš ï¸ åœæ­¢ASRçº¿ç¨‹å¤±è´¥: {e}")
