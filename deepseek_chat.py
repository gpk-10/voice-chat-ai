#!/usr/bin/env python3
"""
DeepSeek èŠå¤©æ¨¡å—
ç”¨äºè¯­éŸ³è¯†åˆ«ç³»ç»Ÿçš„AIå›å¤åŠŸèƒ½
"""

import os   
import uuid
from typing import Dict, Any, List, Optional
from datetime import datetime
import json
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_deepseek import ChatDeepSeek
from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.checkpoint.memory import MemorySaver

class DeepSeekChatModule:
    """DeepSeek èŠå¤©æ¨¡å— - ä¸“ä¸ºè¯­éŸ³ç³»ç»Ÿè®¾è®¡"""
    
    def __init__(self, 
                 api_key: str = None,
                 model_name: str = "deepseek-chat",
                 system_prompt: str = None,
                 max_history_length: int = 20,
                 auto_summarize_threshold: int = 50):
        """
        åˆå§‹åŒ– DeepSeek èŠå¤©æ¨¡å—
        
        Args:
            api_key: DeepSeek API å¯†é’¥
            model_name: æ¨¡å‹åç§°
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            max_history_length: æœ€å¤§ä¿ç•™çš„å¯¹è¯è½®æ•°
            auto_summarize_threshold: è‡ªåŠ¨æ€»ç»“è§¦å‘çš„å¯¹è¯è½®æ•°
        """
        # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥ï¼Œå¦‚æœæ²¡æœ‰ä¼ å…¥çš„è¯
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        
        if not self.api_key:
            raise ValueError("âŒ DeepSeek APIå¯†é’¥æœªè®¾ç½®ï¼è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY æˆ–ä¼ å…¥ api_key å‚æ•°")
        self.model_name = model_name
        self.max_history_length = max_history_length
        self.auto_summarize_threshold = auto_summarize_threshold
        self.conversation_count = 0
        self.conversation_summary = ""
        
        # è¯­éŸ³åŠ©æ‰‹ä¸“ç”¨æç¤ºè¯
        self.system_prompt = system_prompt or """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹å°äº‘ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
1. å‹å–„ã€ä¸“ä¸šä¸”ä¹äºåŠ©äºº
2. å›ç­”ç®€æ´æ˜äº†ï¼Œé€‚åˆè¯­éŸ³äº¤äº’ï¼ˆå»ºè®®æ§åˆ¶åœ¨30å­—ä»¥å†…ï¼Œå¦‚æœè¦æ±‚è¯¦ç»†å›ç­”å¯ä»¥å¢åŠ åˆ°200å­—ä»¥å†…ï¼‰
3. èƒ½å¤Ÿè¿›è¡Œå¤šè½®å¯¹è¯ï¼Œè®°ä½ä¸Šä¸‹æ–‡
4. ä¼˜å…ˆä½¿ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­è¨€è‡ªç„¶æµç•…
5. å¦‚æœä¸ç¡®å®šç­”æ¡ˆï¼Œä¼šè¯šå®åœ°è¯´ä¸çŸ¥é“
6. é¿å…è¿‡äºæŠ€æœ¯æ€§çš„å›ç­”ï¼Œç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€

è¯·æ ¹æ®ç”¨æˆ·çš„è¯­éŸ³è¾“å…¥ï¼Œæä¾›ç®€æ´æœ‰å¸®åŠ©çš„å›å¤ã€‚"""
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['DEEPSEEK_API_KEY'] = self.api_key
        
        # å¯é€‰ï¼šå¯ç”¨ LangSmith ç›‘æ§
        langsmith_key = os.getenv('LANGCHAIN_API_KEY')
        if langsmith_key and os.getenv('LANGCHAIN_TRACING_V2', '').lower() == 'true':
            os.environ['LANGCHAIN_API_KEY'] = langsmith_key
            os.environ['LANGCHAIN_TRACING_V2'] = 'true'
            os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT', 'voice-chat-assistant')
        
        # åˆå§‹åŒ–æ¨¡å‹å’Œå›¾
        self._init_model()
        self._init_graph()
        
        # å¯¹è¯çº¿ç¨‹ID
        self.thread_id = uuid.uuid4().hex
        
        print("âœ… DeepSeek è¯­éŸ³èŠå¤©æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ’­ å¯¹è¯ç®¡ç†: æœ€å¤§ä¿ç•™ {max_history_length} è½®ï¼Œæ¯ {auto_summarize_threshold} è½®è‡ªåŠ¨æ•´ç†")
    
    def _init_model(self):
        """åˆå§‹åŒ– DeepSeek æ¨¡å‹"""
        try:
            self.model = ChatDeepSeek(model=self.model_name)
            print("âœ… ChatDeepSeek æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _init_graph(self):
        """åˆå§‹åŒ– LangGraph çŠ¶æ€å›¾"""
        def chatbot_node(state: MessagesState):
            """èŠå¤©æœºå™¨äººèŠ‚ç‚¹ - å¸¦æ™ºèƒ½å†å²ç®¡ç†"""
            messages = state['messages']
            
            # æ™ºèƒ½å†å²ç®¡ç†
            messages = self._manage_conversation_history(messages)
            
            # å¦‚æœæ²¡æœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œæ·»åŠ ä¸€ä¸ª
            if not messages or not isinstance(messages[0], SystemMessage):
                system_content = self.system_prompt
                # å¦‚æœæœ‰å¯¹è¯æ‘˜è¦ï¼Œæ·»åŠ åˆ°ç³»ç»Ÿæç¤ºä¸­
                if self.conversation_summary:
                    system_content += f"\n\n[å¯¹è¯å†å²æ‘˜è¦: {self.conversation_summary}]"
                messages = [SystemMessage(content=system_content)] + messages
            
            response = self.model.invoke(messages)
            return {'messages': [response]}
        
        # æ„å»ºçŠ¶æ€å›¾
        graph_builder = StateGraph(state_schema=MessagesState)
        graph_builder.add_node('chatbot', chatbot_node)
        graph_builder.add_edge(START, 'chatbot')
        graph_builder.add_edge('chatbot', END)
        
        # ç¼–è¯‘å›¾ï¼ˆä½¿ç”¨å†…å­˜ä¿å­˜å™¨å®ç°çŠ¶æ€æŒä¹…åŒ–ï¼‰
        self.graph = graph_builder.compile(checkpointer=MemorySaver())
        print("âœ… LangGraph çŠ¶æ€å›¾æ„å»ºå®Œæˆ")
    
    def get_ai_response(self, user_text: str) -> str:
        """
        è·å–AIå›å¤ï¼ˆä¸“ä¸ºè¯­éŸ³ç³»ç»Ÿä¼˜åŒ–ï¼Œå¸¦æ™ºèƒ½å†å²ç®¡ç†ï¼‰
        
        Args:
            user_text: ç”¨æˆ·è¯­éŸ³è¯†åˆ«çš„æ–‡æœ¬
            
        Returns:
            AIå›å¤æ–‡æœ¬
        """
        try:
            config = {"configurable": {"thread_id": self.thread_id}}
            
            # å¢åŠ å¯¹è¯è®¡æ•°
            self.conversation_count += 1
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å†å²ç®¡ç†
            if self.conversation_count % self.auto_summarize_threshold == 0:
                print("ğŸ”„ å¯¹è¯è®°å½•è¾ƒå¤šï¼Œæ­£åœ¨æ™ºèƒ½æ•´ç†...")
                self._auto_summarize_history()
            
            # è°ƒç”¨AIè·å–å›å¤
            result = self.graph.invoke(
                {'messages': [HumanMessage(content=user_text)]},
                config
            )
            
            ai_response = result['messages'][-1].content
            
            # è®°å½•å¯¹è¯ï¼ˆå†…éƒ¨ç»Ÿè®¡ï¼Œä¸æ˜¾ç¤ºæ—¥å¿—ï¼‰
            # ä¸»è¦çš„å¯¹è¯æ—¥å¿—ç”±ä¸»ç¨‹åºç®¡ç†
            
            # æ˜¾ç¤ºå¯¹è¯ç»Ÿè®¡
            if self.conversation_count % 10 == 0:
                print(f"ğŸ’­ å¯¹è¯ç»Ÿè®¡: å·²è¿›è¡Œ {self.conversation_count} è½®å¯¹è¯")
            
            return ai_response
            
        except Exception as e:
            error_msg = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
            print(f"âŒ AIå›å¤ç”Ÿæˆå¤±è´¥: {e}")
            return error_msg
    
    def _manage_conversation_history(self, messages: List) -> List:
        """æ™ºèƒ½ç®¡ç†å¯¹è¯å†å²é•¿åº¦"""
        # åˆ†ç¦»ç³»ç»Ÿæ¶ˆæ¯å’Œå¯¹è¯æ¶ˆæ¯
        system_messages = [msg for msg in messages if isinstance(msg, SystemMessage)]
        conversation_messages = [msg for msg in messages if not isinstance(msg, SystemMessage)]
        
        # å¦‚æœå¯¹è¯æ¶ˆæ¯è¶…è¿‡é™åˆ¶ï¼Œä¿ç•™æœ€è¿‘çš„å¯¹è¯
        if len(conversation_messages) > self.max_history_length:
            print(f"ğŸ“ å¯¹è¯å†å²ç®¡ç†: ä¿ç•™æœ€è¿‘ {self.max_history_length} è½®å¯¹è¯")
            conversation_messages = conversation_messages[-self.max_history_length:]
        
        return system_messages + conversation_messages
    
    def _auto_summarize_history(self):
        """è‡ªåŠ¨æ€»ç»“å¯¹è¯å†å²"""
        try:
            config = {"configurable": {"thread_id": self.thread_id}}
            state = self.graph.get_state(config)
            messages = state.values.get('messages', [])
            
            # è·å–å¯¹è¯å†…å®¹
            conversation_text = ""
            for msg in messages:
                if isinstance(msg, HumanMessage):
                    conversation_text += f"ç”¨æˆ·: {msg.content}\n"
                elif isinstance(msg, AIMessage):
                    conversation_text += f"åŠ©æ‰‹: {msg.content}\n"
            
            if conversation_text:
                # ç”Ÿæˆå¯¹è¯æ‘˜è¦
                summary_prompt = f"""è¯·ç®€æ´åœ°æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„å…³é”®ä¿¡æ¯ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š

{conversation_text}

æ‘˜è¦:"""
                
                summary_response = self.model.invoke([HumanMessage(content=summary_prompt)])
                self.conversation_summary = summary_response.content.strip()
                
                print(f"ğŸ“‹ å¯¹è¯æ‘˜è¦å·²ç”Ÿæˆ: {self.conversation_summary}")
                
                # æ¸…ç†æ—§çš„å¯¹è¯å†å²ï¼Œä¿ç•™æ‘˜è¦
                self._cleanup_old_history()
                
        except Exception as e:
            print(f"âš ï¸ å¯¹è¯æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
    
    def _cleanup_old_history(self):
        """æ¸…ç†æ—§çš„å¯¹è¯å†å²"""
        try:
            # åˆ›å»ºæ–°çš„çº¿ç¨‹IDï¼Œä½†ä¿ç•™æ‘˜è¦ä¿¡æ¯
            old_thread_id = self.thread_id
            self.thread_id = uuid.uuid4().hex
            
            # é™é»˜æ¸…ç†å¯¹è¯å†å²
            pass
            
        except Exception as e:
            # é™é»˜å¤„ç†æ¸…ç†å¤±è´¥
            pass
    
    def reset_conversation(self):
        """é‡ç½®å¯¹è¯å†å²"""
        self.thread_id = uuid.uuid4().hex
        self.conversation_count = 0
        self.conversation_summary = ""
        print("ğŸ”„ å¯¹è¯å†å²å·²å®Œå…¨é‡ç½®")
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        config = {"configurable": {"thread_id": self.thread_id}}
        
        try:
            state = self.graph.get_state(config)
            messages = state.values.get('messages', [])
            
            history = []
            for msg in messages:
                if isinstance(msg, HumanMessage):
                    history.append({"role": "user", "content": msg.content})
                elif isinstance(msg, AIMessage):
                    history.append({"role": "assistant", "content": msg.content})
            
            return history
        except:
            return []
    
    def save_conversation(self, filename: str = None) -> str:
        """ä¿å­˜å¯¹è¯åˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"voice_conversation_{timestamp}.json"
        
        history = self.get_conversation_history()
        
        conversation_data = {
            "timestamp": datetime.now().isoformat(),
            "model": self.model_name,
            "thread_id": self.thread_id,
            "type": "voice_conversation",
            "history": history
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(conversation_data, f, ensure_ascii=False, indent=2)
        
            print(f"ğŸ’¾ å¯¹è¯å·²ä¿å­˜åˆ°: {filename}")
            return filename
        except Exception as e:
            print(f"âŒ ä¿å­˜å¯¹è¯å¤±è´¥: {e}")
            return ""
