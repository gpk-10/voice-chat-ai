#!/usr/bin/env python3
"""
VAD (Voice Activity Detection) å¤„ç†æ¨¡å—
"""

import webrtcvad
import numpy as np

class VADProcessor:
    def __init__(self, vad_mode=1, samplerate=16000, channels=2):
        """
        åˆå§‹åŒ–VADå¤„ç†å™¨
        
        Args:
            vad_mode: VADæ¨¡å¼ (0-3, æ•°å­—è¶Šå¤§è¶Šæ•æ„Ÿ)
            samplerate: é‡‡æ ·ç‡
            channels: å£°é“æ•°
        """
        self.vad_mode = vad_mode
        self.samplerate = samplerate
        self.channels = channels
        
        # åˆå§‹åŒ– WebRTC VAD
        self.vad = webrtcvad.Vad()
        self.vad.set_mode(self.vad_mode)
        
        print(f'ğŸ¯ VADåˆå§‹åŒ–å®Œæˆ: æ¨¡å¼={vad_mode}, é‡‡æ ·ç‡={samplerate}Hz, å£°é“={channels}')
    
    def stereo_to_mono(self, stereo_data):
        """å°†åŒå£°é“éŸ³é¢‘è½¬æ¢ä¸ºå•å£°é“ - ä¿®å¤éŸ³è´¨é—®é¢˜"""
        try:
            audio_array = np.frombuffer(stereo_data, dtype=np.int16)
            if self.channels == 2:
                # é‡å¡‘ä¸ºåŒå£°é“æ•°ç»„ [å·¦, å³, å·¦, å³, ...]
                stereo_array = audio_array.reshape(-1, 2)
                # åªå–å·¦å£°é“ï¼Œé¿å…å¹³å‡é€ æˆçš„éŸ³è´¨æŸå¤±
                mono_array = stereo_array[:, 0]  # å–å·¦å£°é“
            else:
                mono_array = audio_array
            return mono_array.tobytes()
        except Exception as e:
            print(f"âŒ åŒå£°é“è½¬å•å£°é“å¤±è´¥: {e}")
            return stereo_data
    
    def check_vad_activity(self, audio_data):
        """
        æ£€æµ‹VADæ´»åŠ¨ - æ”¹å–„ç¨³å®šæ€§
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ® (bytes)
            
        Returns:
            tuple: (æ˜¯å¦æ£€æµ‹åˆ°è¯­éŸ³, è¯­éŸ³å—æ•°, æ€»å—æ•°)
        """
        try:
            # åŒå£°é“è½¬å•å£°é“ç”¨äºVADæ£€æµ‹
            mono_data = self.stereo_to_mono(audio_data)
            
            # æ£€æŸ¥æ•°æ®é•¿åº¦
            if len(mono_data) < 640:  # è‡³å°‘20msçš„æ•°æ®
                return False, 0, 0
            
            # å°†éŸ³é¢‘æ•°æ®åˆ†å—æ£€æµ‹ï¼Œè®¾ç½®æœ‰æ•ˆæ¿€æ´»ç‡rate=50%
            num, rate = 0, 0.5
            step = int(self.samplerate * 0.02) * 2  # 20ms å—å¤§å° * 2å­—èŠ‚(int16)
            
            # ç¡®ä¿æ­¥é•¿ä¸ä¸º0
            if step <= 0:
                step = 640  # é»˜è®¤640å­—èŠ‚ (20ms @ 16kHzï¼Œå®‰å…¨åå¤‡å€¼)
            
            total_chunks = len(mono_data) // step
            if total_chunks == 0:
                return False, 0, 0
                
            flag_rate = max(1, round(rate * total_chunks))  # è‡³å°‘éœ€è¦1ä¸ªå—

            for i in range(0, len(mono_data), step):
                chunk = mono_data[i:i + step]
                if len(chunk) == step:
                    try:
                        if self.vad.is_speech(chunk, sample_rate=self.samplerate):
                            num += 1
                    except Exception:
                        # VADæ£€æµ‹å¤±è´¥æ—¶è·³è¿‡è¯¥å—ï¼Œé™é»˜å¤„ç†ä¿è¯ç¨³å®šæ€§
                        continue

            is_speech = num >= flag_rate
            
            return is_speech, num, total_chunks
            
        except Exception as e:
            print(f"âŒ VADæ£€æµ‹é”™è¯¯: {e}")
            return False, 0, 0
    
    def calculate_audio_amplitude(self, audio_data):
        """è®¡ç®—éŸ³é¢‘å¹…åº¦"""
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        max_amplitude = np.max(np.abs(audio_array))
        normalized_amplitude = max_amplitude / 32768.0
        return normalized_amplitude
